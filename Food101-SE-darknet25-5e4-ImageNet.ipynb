{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from torch import nn, optim\n",
    "from autoaugment import ImageNetPolicy\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gpus = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpus = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, planes, ratio):\n",
    "\n",
    "      super(SEBlock, self).__init__()\n",
    "\n",
    "      self.se_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "      self.se_fc1 = nn.Linear(planes, planes // ratio)\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      self.se_fc2 = nn.Linear(planes // ratio, planes)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "      out = self.se_pool(x)\n",
    "      out = torch.flatten(out, 1)\n",
    "      out = self.se_fc1(out)\n",
    "      #print(out.shape)\n",
    "      out = F.relu(out)\n",
    "      out = self.se_fc2(out)\n",
    "      out = torch.sigmoid(out)\n",
    "      out = out.view(out.size(0), out.size(1), 1, 1)\n",
    "      #print(x.shape)\n",
    "      #print(out.shape)\n",
    "      out = torch.mul(out.expand_as(x), x)\n",
    "\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=True):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        pad = 0\n",
    "        if padding :\n",
    "            pad = (self.kernel_size - 1) // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding=pad, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_planes, momentum=0.99)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.conv(x)\n",
    "        output = self.batchnorm(output)\n",
    "        output = self.leaky_relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarknetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, out_planes):\n",
    "\n",
    "        super(DarknetBlock, self).__init__()\n",
    "        self.inplanes = out_planes * 2\n",
    "        self.conv1 = ConvBlock(self.inplanes, out_planes, 1)\n",
    "        self.conv2 = ConvBlock(out_planes, self.inplanes, 3)\n",
    "        self.se = SEBlock(self.inplanes, ratio=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.se(output)\n",
    "        output = output + shortcut\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "\n",
    "        super(Darknet, self).__init__()   \n",
    "\n",
    "        self.conv_block1 = ConvBlock(3, 32, 3, 1)\n",
    "        self.conv_block2 = ConvBlock(32, 64, 3, 2)\n",
    "\n",
    "        self.dark_block1 = DarknetBlock(32)\n",
    "\n",
    "        self.conv_block3 = ConvBlock(64, 128, 3, 2)\n",
    "\n",
    "        self.dark_layer1 = self._make_blocks(2, 64)\n",
    "        \n",
    "        self.conv_block4 = ConvBlock(128, 256, 3, 2)\n",
    "\n",
    "        self.dark_layer2 = self._make_blocks(2, 128)\n",
    "\n",
    "        self.conv_block5 = ConvBlock(256, 512, 3, 2)\n",
    "\n",
    "        self.dark_layer3 = self._make_blocks(2, 256)\n",
    "\n",
    "        self.conv_block6 = ConvBlock(512, 1024, 3, 2)\n",
    "\n",
    "        self.dark_layer4 = self._make_blocks(2, 512)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_blocks(self, num_blocks, out_planes):\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(DarknetBlock(out_planes))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x, feature=False):\n",
    "\n",
    "        output = self.conv_block1(x)\n",
    "        output = self.conv_block2(output)\n",
    "\n",
    "        output = self.dark_block1(output)\n",
    "\n",
    "        output = self.conv_block3(output)\n",
    "\n",
    "        output = self.dark_layer1(output)\n",
    "\n",
    "        output = self.conv_block4(output)\n",
    "\n",
    "        output = self.dark_layer2(output)\n",
    "\n",
    "        output = self.conv_block5(output)\n",
    "\n",
    "        output = self.dark_layer3(output)\n",
    "\n",
    "        output = self.conv_block6(output)\n",
    "\n",
    "        output = self.dark_layer4(output)\n",
    "\n",
    "        output = self.avgpool(output)\n",
    "\n",
    "        output = torch.flatten(output, 1)\n",
    "        \n",
    "        if feature:\n",
    "            return output\n",
    "\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1,3,224,224))\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 101])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20705145"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using apex synced BN\n"
     ]
    }
   ],
   "source": [
    "import apex\n",
    "print(\"using apex synced BN\")\n",
    "model = apex.parallel.convert_syncbn_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1., momentum=0.9, weight_decay=5e-4, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O3:  Pure FP16 training.\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : False\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "model, optimizer = amp.initialize(model.cuda(), optimizer, opt_level='O3',keep_batchnorm_fp32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#from autoaugment import ImageNetPolicy\n",
    "\n",
    "def get_transform(random_crop=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        #mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "        #std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n",
    "        [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    transform = []\n",
    "    transform.append(transforms.Resize(256))\n",
    "    if random_crop:\n",
    "        #transform.append(transforms.RandomRotation(30))\n",
    "        transform.append(transforms.RandomResizedCrop(224))\n",
    "        transform.append(transforms.RandomHorizontalFlip())\n",
    "        transform.append(ImageNetPolicy())\n",
    "        #transform.append(transforms.ColorJitter(hue=.05, saturation=.05),)\n",
    "    else:\n",
    "        transform.append(transforms.CenterCrop(224))\n",
    "    transform.append(transforms.ToTensor())\n",
    "    transform.append(normalize)\n",
    "    return transforms.Compose(transform)\n",
    "'''\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image_id, sample, target) where target is class_index of\n",
    "                the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        #print(path)\n",
    "        #print(target)\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        image_id = path.split('/')[-1]\n",
    "\n",
    "        return image_id, sample, target\n",
    "''' \n",
    "data_dir = './data/food101/'\n",
    "train_data = datasets.ImageFolder(data_dir + 'train', transform=get_transform(random_crop=True))\n",
    "test_data = datasets.ImageFolder(data_dir + 'test', transform=get_transform(random_crop=False))\n",
    "#testdata=datasets.ImageFolder(data_dir + r'\\test', transform=test_transforms)\n",
    "\n",
    "#trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(test_data, batch_size=128)\n",
    "#test_loader=torch.utils.data.DataLoader(testdata, batch_size=64)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "#data_dir = 'train/train_data'\n",
    "\n",
    "#dataset = CustomDataset(data_dir, transform=get_transform(random_crop=True))\n",
    "\n",
    "#split_size = int(len(dataset) * 0.9)\n",
    "#train_set, valid_set = data.random_split(dataset, [split_size, len(dataset) - split_size])\n",
    "tr_loader = data.DataLoader(dataset=train_data,\n",
    "                            batch_size=256,\n",
    "                            #sampler = RandomIdentitySampler(train_set, 4),\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=16)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=test_data,\n",
    "                             batch_size=256,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True,                             \n",
    "                             num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 224, 224])\n",
      "tensor([ 38,  63,   8,  36,  35,  89,  54,  36,  96,  63,  48,  12,  42,  91,\n",
      "         80,  88,  24,   9,  31,  46,  25,  48,  39,  76,   3,  56,  52,  93,\n",
      "         55,   7,  89,  76,   7,  10,  76,  31,   5,  29,   8,  84,  94,  84,\n",
      "          7,   6,  31,  58,  60,  70,   0,  52,   2,  12,  27,  92,  19,  12,\n",
      "         15,   5,  17,  28,  99,  72,  15,  30,  67,  86,  57,  58,  47,  55,\n",
      "         56,  29,  31,  85,   2,   2,  26,  56,  83,  46,  34,  19,  58,  51,\n",
      "         34,  98,  79,  18,  15,  76,  11,  40,  85,  47,  38,   5,  36,  27,\n",
      "         82,   5,   9,  99,  81,  87,  81,   1,  56,  73,   4,  34,  55,   2,\n",
      "         72,  71,   6,  75,  50,  67,  91,  94,  72,   6,  27,  28,  65,  93,\n",
      "         32,  56,  13,  56,  29,  29,  90,  25,  30,  73,  86,  32,  23,  73,\n",
      "         42,  86,  57,  65,  50,  51,  78,  60,  37,  95,  41,  25,  94,  27,\n",
      "         42,  72,  84,  40,  56,  64,  41,  47,  37,  83,  89,  64,  76,  37,\n",
      "         66,  98,  14,  19,  24,  22,  80,  69,  63,  72,  13,  14,   4,  29,\n",
      "         59,   4,  48,  43,  29,  62,  65,  84,  96,  35,  81,  12,  90,  59,\n",
      "         66,  24,  29,  29,  59,   7,  31,  90,  24,  34,  98,   7,  38,  51,\n",
      "         89,  65,  63,  85,  34,  19,   3,  13,  69,  74,  14,  36,   3,  77,\n",
      "         25,  91,  56,   5,  97,  99,  75,  52,   2,  13,  10,   1,  97,  30,\n",
      "         26,  18,  65, 100,  87,  61,   7,  36,  82,  31,  86,  67,  88,  96,\n",
      "         51,  38,  19,  57])\n",
      "torch.Size([256, 3, 224, 224])\n",
      "tensor([85, 24, 16, 62,  2,  1, 28, 12, 65,  8, 16,  3, 17, 97, 71, 82, 44, 23,\n",
      "        61, 94,  0, 84, 60, 63, 76, 10, 54, 81, 15, 83,  5, 51, 32, 50, 77, 46,\n",
      "        41, 35, 98,  6, 35,  9, 58, 98, 30, 46, 77,  6, 38, 49, 41, 58, 55,  6,\n",
      "        61, 51, 32,  4, 66, 79, 31, 22, 82, 49, 75, 82, 72, 92, 59,  5, 27, 18,\n",
      "        78, 37, 40, 69, 85,  2, 67, 12, 64, 81, 13, 57, 36, 46, 41, 92, 13, 91,\n",
      "         2, 77, 89, 11,  0, 91, 96, 98, 70, 86, 42,  8, 38, 75, 93, 83, 40, 29,\n",
      "        82, 33, 86, 21, 38, 97, 83, 79, 61, 29, 89, 85, 40, 74, 16, 39, 14, 61,\n",
      "        87, 18, 18, 81, 22, 82, 63, 58, 43, 32, 33, 86, 45, 21, 37,  1, 28, 89,\n",
      "        41, 86, 39, 30, 25, 57,  1,  2, 45, 27, 38, 20, 91, 49, 35, 96, 84, 71,\n",
      "        93, 71, 69,  0, 96, 29, 50, 75, 36, 58, 36, 40, 21, 35,  7, 11, 41, 91,\n",
      "         2, 48, 35, 60, 34, 72, 38, 21, 70, 27, 19, 13, 23, 40, 69, 35,  1, 79,\n",
      "        90, 94, 65, 16, 30, 33,  4,  8,  5,  8, 95, 62, 82, 12, 45, 32, 33, 62,\n",
      "         2, 30,  4, 60, 44, 48, 72, 52, 58, 25, 87, 90, 67, 62, 71, 83, 89, 79,\n",
      "        23, 46, 10, 81, 80, 14, 64, 69, 14, 94, 99, 27, 85, 87, 19, 30, 88, 65,\n",
      "        73, 40, 69, 10])\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    inputs, labels = next(iter(tr_loader))\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "model.train()\n",
    "for _ in range(2):\n",
    "    inputs, labels = next(iter(tr_loader))\n",
    "    print(1)\n",
    "    inputs = inputs.cuda(non_blocking=True)        \n",
    "    labels = labels.cuda(non_blocking=True)    \n",
    "    print(2)    \n",
    "    logits = model(inputs)\n",
    "    print(3)                       \n",
    "    loss = criterion(logits, labels)                   \n",
    "    print(4)                   \n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "    print(5)                            \n",
    "    model.zero_grad()\n",
    "    print(10)                                \n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(tr_loader)\n",
    "                                                , epochs=30, pct_start=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 99/296]\tBatch 329.551 (173.891)\tData 329.257 (173.591)\tLoss 4.48752 (4.55249)\tAcc@1   2.73 (  2.68)\tAcc@5  13.28 ( 10.00)\tLearningRate 0.00475 (0.00425)\n",
      "Epoch: [0][199/296]\tBatch 613.670 (320.220)\tData 613.376 (319.922)\tLoss 4.37504 (4.48318)\tAcc@1   3.91 (  3.65)\tAcc@5  14.84 ( 12.75)\tLearningRate 0.00698 (0.00500)\n",
      "0:14:10.467842 elapsed for 1\n",
      "Epoch: [1][ 99/296]\tBatch 45.864 (349.759)\tData 45.569 (349.460)\tLoss 4.15750 (4.40601)\tAcc@1   7.81 (  4.66)\tAcc@5  21.88 ( 15.58)\tLearningRate 0.01531 (0.00785)\n",
      "Epoch: [1][199/296]\tBatch 84.419 (292.406)\tData 84.095 (292.104)\tLoss 4.23987 (4.37232)\tAcc@1   7.81 (  5.12)\tAcc@5  23.44 ( 16.72)\tLearningRate 0.02134 (0.00995)\n",
      "0:01:59.898964 elapsed for 2\n",
      "Epoch: [2][ 99/296]\tBatch 46.779 (227.691)\tData 46.472 (227.386)\tLoss 3.95070 (4.30554)\tAcc@1  11.72 (  6.05)\tAcc@5  28.52 ( 18.89)\tLearningRate 0.03572 (0.01515)\n",
      "Epoch: [2][199/296]\tBatch 85.767 (207.291)\tData 85.456 (206.986)\tLoss 3.88253 (4.26968)\tAcc@1  12.50 (  6.56)\tAcc@5  28.12 ( 20.03)\tLearningRate 0.04393 (0.01827)\n",
      "0:02:01.696516 elapsed for 3\n",
      "Epoch: [3][ 99/296]\tBatch 45.538 (179.036)\tData 45.211 (178.729)\tLoss 3.73691 (4.19365)\tAcc@1  12.50 (  7.74)\tAcc@5  32.81 ( 22.42)\tLearningRate 0.06049 (0.02501)\n",
      "Epoch: [3][199/296]\tBatch 85.190 (168.567)\tData 84.895 (168.260)\tLoss 3.75053 (4.15047)\tAcc@1  15.23 (  8.45)\tAcc@5  32.81 ( 23.73)\tLearningRate 0.06868 (0.02866)\n",
      "0:02:00.592429 elapsed for 4\n",
      "Epoch: [4][ 99/296]\tBatch 46.310 (152.666)\tData 45.990 (152.359)\tLoss 3.59715 (4.06133)\tAcc@1  16.80 (  9.87)\tAcc@5  41.41 ( 26.34)\tLearningRate 0.08299 (0.03590)\n",
      "Epoch: [4][199/296]\tBatch 85.279 (146.389)\tData 84.985 (146.081)\tLoss 3.38385 (4.01603)\tAcc@1  20.70 ( 10.64)\tAcc@5  42.97 ( 27.66)\tLearningRate 0.08896 (0.03953)\n",
      "0:01:59.798402 elapsed for 5\n",
      "Epoch: [5][ 99/296]\tBatch 45.099 (136.169)\tData 44.796 (135.861)\tLoss 3.06251 (3.92804)\tAcc@1  27.34 ( 12.15)\tAcc@5  51.17 ( 30.13)\tLearningRate 0.09717 (0.04622)\n",
      "Epoch: [5][199/296]\tBatch 83.591 (131.897)\tData 83.234 (131.589)\tLoss 3.02279 (3.88411)\tAcc@1  24.61 ( 12.92)\tAcc@5  54.69 ( 31.35)\tLearningRate 0.09932 (0.04933)\n",
      "0:01:59.270267 elapsed for 6\n",
      "Epoch: [6][ 99/296]\tBatch 44.932 (124.762)\tData 44.637 (124.454)\tLoss 3.03682 (3.80142)\tAcc@1  25.78 ( 14.39)\tAcc@5  56.25 ( 33.63)\tLearningRate 0.09995 (0.05461)\n",
      "Epoch: [6][199/296]\tBatch 84.793 (121.760)\tData 84.496 (121.451)\tLoss 3.09501 (3.76108)\tAcc@1  24.61 ( 15.12)\tAcc@5  51.17 ( 34.71)\tLearningRate 0.09980 (0.05690)\n",
      "0:01:59.746217 elapsed for 7\n",
      "Epoch: [7][ 99/296]\tBatch 46.037 (116.538)\tData 45.742 (116.230)\tLoss 2.99445 (3.68346)\tAcc@1  26.56 ( 16.54)\tAcc@5  52.34 ( 36.77)\tLearningRate 0.09923 (0.06075)\n",
      "Epoch: [7][199/296]\tBatch 84.502 (114.278)\tData 84.201 (113.970)\tLoss 2.86089 (3.64552)\tAcc@1  32.42 ( 17.25)\tAcc@5  57.42 ( 37.76)\tLearningRate 0.09880 (0.06243)\n",
      "0:01:59.451144 elapsed for 8\n",
      "Epoch: [8][ 99/296]\tBatch 45.628 (110.258)\tData 45.333 (109.949)\tLoss 2.65127 (3.57549)\tAcc@1  32.42 ( 18.56)\tAcc@5  63.28 ( 39.56)\tLearningRate 0.09767 (0.06528)\n",
      "Epoch: [8][199/296]\tBatch 82.527 (108.456)\tData 82.156 (108.147)\tLoss 2.72610 (3.54099)\tAcc@1  38.28 ( 19.21)\tAcc@5  60.16 ( 40.44)\tLearningRate 0.09696 (0.06653)\n",
      "0:01:57.502779 elapsed for 9\n",
      "Epoch: [9][ 99/296]\tBatch 45.732 (105.202)\tData 45.437 (104.894)\tLoss 2.56387 (3.47641)\tAcc@1  36.72 ( 20.43)\tAcc@5  64.84 ( 42.06)\tLearningRate 0.09529 (0.06863)\n",
      "Epoch: [9][199/296]\tBatch 83.360 (103.787)\tData 83.052 (103.479)\tLoss 2.42643 (3.44482)\tAcc@1  39.45 ( 21.05)\tAcc@5  67.97 ( 42.85)\tLearningRate 0.09431 (0.06954)\n",
      "0:01:58.650595 elapsed for 10\n",
      "Epoch: [10][ 99/296]\tBatch 45.975 (101.208)\tData 45.642 (100.899)\tLoss 2.47203 (3.38668)\tAcc@1  39.45 ( 22.17)\tAcc@5  69.14 ( 44.28)\tLearningRate 0.09214 (0.07106)\n",
      "Epoch: [10][199/296]\tBatch 83.317 (100.050)\tData 83.010 (99.741)\tLoss 2.55383 (3.35742)\tAcc@1  37.89 ( 22.74)\tAcc@5  66.02 ( 45.00)\tLearningRate 0.09091 (0.07171)\n",
      "0:01:58.074510 elapsed for 11\n",
      "Epoch: [11][ 99/296]\tBatch 45.178 (97.863)\tData 44.884 (97.554)\tLoss 2.42555 (3.30404)\tAcc@1  47.66 ( 23.80)\tAcc@5  64.45 ( 46.30)\tLearningRate 0.08827 (0.07275)\n",
      "Epoch: [11][199/296]\tBatch 84.243 (96.902)\tData 83.927 (96.593)\tLoss 2.52454 (3.27783)\tAcc@1  39.45 ( 24.31)\tAcc@5  65.62 ( 46.93)\tLearningRate 0.08681 (0.07318)\n",
      "0:01:58.520052 elapsed for 12\n",
      "Epoch: [12][ 99/296]\tBatch 45.423 (95.098)\tData 45.128 (94.789)\tLoss 2.27204 (3.22813)\tAcc@1  44.14 ( 25.29)\tAcc@5  69.92 ( 48.12)\tLearningRate 0.08374 (0.07383)\n",
      "Epoch: [12][199/296]\tBatch 83.462 (94.274)\tData 83.159 (93.965)\tLoss 2.49216 (3.20416)\tAcc@1  39.06 ( 25.77)\tAcc@5  62.50 ( 48.69)\tLearningRate 0.08208 (0.07407)\n",
      "0:01:58.591931 elapsed for 13\n",
      "Epoch: [13][ 99/296]\tBatch 45.538 (92.719)\tData 45.236 (92.410)\tLoss 2.37385 (3.15862)\tAcc@1  45.31 ( 26.67)\tAcc@5  64.84 ( 49.75)\tLearningRate 0.07864 (0.07438)\n",
      "Epoch: [13][199/296]\tBatch 83.806 (92.022)\tData 83.504 (91.713)\tLoss 2.32246 (3.13581)\tAcc@1  46.09 ( 27.12)\tAcc@5  67.97 ( 50.28)\tLearningRate 0.07680 (0.07447)\n",
      "0:01:58.605789 elapsed for 14\n",
      "Epoch: [14][ 99/296]\tBatch 45.656 (90.699)\tData 45.361 (90.390)\tLoss 2.23065 (3.09399)\tAcc@1  42.19 ( 27.94)\tAcc@5  72.27 ( 51.25)\tLearningRate 0.07304 (0.07449)\n",
      "Epoch: [14][199/296]\tBatch 83.956 (90.101)\tData 83.653 (89.791)\tLoss 2.16038 (3.07296)\tAcc@1  43.75 ( 28.36)\tAcc@5  73.83 ( 51.73)\tLearningRate 0.07106 (0.07443)\n",
      "0:01:58.797481 elapsed for 15\n",
      "Epoch: [15][ 99/296]\tBatch 45.626 (88.947)\tData 45.331 (88.637)\tLoss 2.21050 (3.03348)\tAcc@1  51.17 ( 29.16)\tAcc@5  71.88 ( 52.64)\tLearningRate 0.06705 (0.07420)\n",
      "Epoch: [15][199/296]\tBatch 83.825 (88.420)\tData 83.516 (88.111)\tLoss 2.01287 (3.01419)\tAcc@1  48.44 ( 29.55)\tAcc@5  74.61 ( 53.08)\tLearningRate 0.06496 (0.07402)\n",
      "0:01:58.464744 elapsed for 16\n",
      "Epoch: [16][ 99/296]\tBatch 44.975 (87.389)\tData 44.585 (87.079)\tLoss 2.07413 (2.97666)\tAcc@1  45.70 ( 30.32)\tAcc@5  72.66 ( 53.92)\tLearningRate 0.06077 (0.07357)\n",
      "Epoch: [16][199/296]\tBatch 82.465 (86.906)\tData 82.170 (86.597)\tLoss 2.03210 (2.95808)\tAcc@1  49.22 ( 30.71)\tAcc@5  74.61 ( 54.34)\tLearningRate 0.05860 (0.07329)\n",
      "0:01:57.880780 elapsed for 17\n",
      "Epoch: [17][ 99/296]\tBatch 45.337 (85.987)\tData 45.037 (85.678)\tLoss 1.91843 (2.92292)\tAcc@1  52.73 ( 31.42)\tAcc@5  75.00 ( 55.13)\tLearningRate 0.05431 (0.07265)\n",
      "Epoch: [17][199/296]\tBatch 83.025 (85.577)\tData 82.701 (85.268)\tLoss 2.07622 (2.90596)\tAcc@1  49.22 ( 31.77)\tAcc@5  73.83 ( 55.51)\tLearningRate 0.05210 (0.07227)\n",
      "0:01:58.270164 elapsed for 18\n",
      "Epoch: [18][ 99/296]\tBatch 44.638 (84.760)\tData 44.287 (84.451)\tLoss 1.90428 (2.87258)\tAcc@1  53.12 ( 32.46)\tAcc@5  75.39 ( 56.25)\tLearningRate 0.04777 (0.07147)\n",
      "Epoch: [18][199/296]\tBatch 82.982 (84.387)\tData 82.679 (84.078)\tLoss 1.96335 (2.85594)\tAcc@1  50.39 ( 32.81)\tAcc@5  76.56 ( 56.62)\tLearningRate 0.04556 (0.07102)\n",
      "0:01:58.277722 elapsed for 19\n",
      "Epoch: [19][ 99/296]\tBatch 45.832 (83.651)\tData 45.526 (83.342)\tLoss 2.03457 (2.82360)\tAcc@1  47.66 ( 33.48)\tAcc@5  75.39 ( 57.32)\tLearningRate 0.04127 (0.07007)\n",
      "Epoch: [19][199/296]\tBatch 84.236 (83.335)\tData 83.940 (83.025)\tLoss 2.16845 (2.80807)\tAcc@1  44.14 ( 33.80)\tAcc@5  71.88 ( 57.66)\tLearningRate 0.03910 (0.06956)\n",
      "0:01:58.511675 elapsed for 20\n",
      "Epoch: [20][ 99/296]\tBatch 44.617 (82.670)\tData 44.322 (82.360)\tLoss 1.66478 (2.77777)\tAcc@1  55.47 ( 34.44)\tAcc@5  80.08 ( 58.31)\tLearningRate 0.03492 (0.06850)\n",
      "Epoch: [20][199/296]\tBatch 83.628 (82.363)\tData 83.327 (82.053)\tLoss 1.58464 (2.76269)\tAcc@1  57.03 ( 34.75)\tAcc@5  83.59 ( 58.63)\tLearningRate 0.03282 (0.06793)\n",
      "0:01:58.489796 elapsed for 21\n",
      "Epoch: [21][ 99/296]\tBatch 44.853 (81.758)\tData 44.558 (81.448)\tLoss 1.82864 (2.73312)\tAcc@1  53.91 ( 35.37)\tAcc@5  75.00 ( 59.26)\tLearningRate 0.02882 (0.06678)\n",
      "Epoch: [21][199/296]\tBatch 82.782 (81.475)\tData 82.455 (81.166)\tLoss 1.61333 (2.71827)\tAcc@1  60.94 ( 35.69)\tAcc@5  82.03 ( 59.57)\tLearningRate 0.02684 (0.06617)\n",
      "0:01:58.071106 elapsed for 22\n",
      "Epoch: [22][ 99/296]\tBatch 44.695 (80.917)\tData 44.399 (80.607)\tLoss 1.62589 (2.68927)\tAcc@1  58.59 ( 36.30)\tAcc@5  83.59 ( 60.18)\tLearningRate 0.02309 (0.06495)\n",
      "Epoch: [22][199/296]\tBatch 83.063 (80.665)\tData 82.767 (80.356)\tLoss 1.41433 (2.67468)\tAcc@1  63.28 ( 36.61)\tAcc@5  84.77 ( 60.48)\tLearningRate 0.02126 (0.06431)\n",
      "0:01:57.688186 elapsed for 23\n",
      "Epoch: [23][ 99/296]\tBatch 44.921 (80.149)\tData 44.581 (79.840)\tLoss 1.71480 (2.64657)\tAcc@1  57.81 ( 37.20)\tAcc@5  80.86 ( 61.06)\tLearningRate 0.01782 (0.06304)\n",
      "Epoch: [23][199/296]\tBatch 82.946 (79.920)\tData 82.651 (79.610)\tLoss 1.52902 (2.63205)\tAcc@1  60.16 ( 37.52)\tAcc@5  85.55 ( 61.36)\tLearningRate 0.01616 (0.06238)\n",
      "0:01:58.375139 elapsed for 24\n",
      "Epoch: [24][ 99/296]\tBatch 46.059 (79.451)\tData 45.748 (79.141)\tLoss 1.58263 (2.60357)\tAcc@1  60.55 ( 38.13)\tAcc@5  82.42 ( 61.93)\tLearningRate 0.01310 (0.06108)\n",
      "Epoch: [24][199/296]\tBatch 83.586 (79.252)\tData 83.292 (78.942)\tLoss 1.70930 (2.58922)\tAcc@1  54.30 ( 38.44)\tAcc@5  82.42 ( 62.22)\tLearningRate 0.01165 (0.06042)\n",
      "0:01:58.348538 elapsed for 25\n",
      "Epoch: [25][ 99/296]\tBatch 45.338 (78.824)\tData 45.040 (78.515)\tLoss 1.46599 (2.56126)\tAcc@1  62.11 ( 39.05)\tAcc@5  83.98 ( 62.77)\tLearningRate 0.00901 (0.05911)\n",
      "Epoch: [25][199/296]\tBatch 83.003 (78.632)\tData 82.708 (78.322)\tLoss 1.33462 (2.54670)\tAcc@1  64.06 ( 39.37)\tAcc@5  86.72 ( 63.05)\tLearningRate 0.00779 (0.05844)\n",
      "0:01:58.554388 elapsed for 26\n",
      "Epoch: [26][ 99/296]\tBatch 45.756 (78.235)\tData 45.440 (77.926)\tLoss 1.36097 (2.51870)\tAcc@1  61.33 ( 39.98)\tAcc@5  85.16 ( 63.60)\tLearningRate 0.00563 (0.05714)\n",
      "Epoch: [26][199/296]\tBatch 83.160 (78.058)\tData 82.845 (77.748)\tLoss 1.33490 (2.50407)\tAcc@1  66.02 ( 40.30)\tAcc@5  85.94 ( 63.88)\tLearningRate 0.00465 (0.05648)\n",
      "0:01:57.682415 elapsed for 27\n",
      "Epoch: [27][ 99/296]\tBatch 45.330 (77.687)\tData 45.034 (77.377)\tLoss 1.18980 (2.47553)\tAcc@1  70.70 ( 40.92)\tAcc@5  88.67 ( 64.43)\tLearningRate 0.00300 (0.05520)\n",
      "Epoch: [27][199/296]\tBatch 84.344 (77.529)\tData 84.050 (77.219)\tLoss 1.32410 (2.46108)\tAcc@1  68.36 ( 41.24)\tAcc@5  85.16 ( 64.70)\tLearningRate 0.00229 (0.05456)\n",
      "0:01:59.376934 elapsed for 28\n",
      "Epoch: [28][ 99/296]\tBatch 45.409 (77.200)\tData 45.109 (76.891)\tLoss 1.34217 (2.43297)\tAcc@1  66.41 ( 41.87)\tAcc@5  87.11 ( 65.23)\tLearningRate 0.00117 (0.05333)\n",
      "Epoch: [28][199/296]\tBatch 83.808 (77.049)\tData 83.498 (76.740)\tLoss 1.18876 (2.41882)\tAcc@1  69.92 ( 42.18)\tAcc@5  88.67 ( 65.49)\tLearningRate 0.00075 (0.05271)\n",
      "0:01:57.934221 elapsed for 29\n",
      "Epoch: [29][ 99/296]\tBatch 45.654 (76.730)\tData 45.340 (76.420)\tLoss 1.18916 (2.39137)\tAcc@1  68.75 ( 42.79)\tAcc@5  89.45 ( 66.00)\tLearningRate 0.00019 (0.05153)\n",
      "Epoch: [29][199/296]\tBatch 83.946 (76.590)\tData 83.634 (76.281)\tLoss 1.16378 (2.37766)\tAcc@1  69.92 ( 43.10)\tAcc@5  87.89 ( 66.25)\tLearningRate 0.00004 (0.05094)\n",
      "0:01:57.960749 elapsed for 30\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "high = 0.0\n",
    "epoch_time = AverageMeter('Epoch', ':6.3f')\n",
    "batch_time = AverageMeter('Batch', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "losses = AverageMeter('Loss', ':.5f')\n",
    "learning_rates = AverageMeter('LearningRate', ':.5f')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    time_ = datetime.datetime.now()    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    progress = ProgressMeter(\n",
    "        len(tr_loader),\n",
    "        [batch_time, data_time, losses, top1, top5, learning_rates],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    end = time.time()    \n",
    "    for i, (inputs, labels) in enumerate(tr_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #print(inputs.shape)\n",
    "        #print(labels.shape)\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs = inputs.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #_, preds = torch.max(outputs, 1)\n",
    "        #loss.backward()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        acc1, acc5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        learning_rates.update(scheduler.get_lr()[0])        \n",
    "        top1.update(acc1[0], inputs.size(0))\n",
    "        top5.update(acc5[0], inputs.size(0))\n",
    "\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            progress.display(i)\n",
    "            #running_loss = 0.0\n",
    "    elapsed = datetime.datetime.now() - time_\n",
    "    print('{} elapsed for {}'.format(elapsed, epoch+1))\n",
    "\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': loss,    \n",
    "    \n",
    "}, './checkpoint/food_darknet25_fp16_5e4_ep030.b0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_val(model, val_loader):\n",
    "    correct = 0\n",
    "    total = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_results = classification_val(model, val_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268118811881188"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161584158415841"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828868760840239"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002308887647354633"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7867604548082482,\n",
       " 0.7841587974561572,\n",
       " 0.783773366737329,\n",
       " 0.7795336288302178,\n",
       " 0.7843515128155714,\n",
       " 0.7842551551358643,\n",
       " 0.7832915783387936,\n",
       " 0.7815571401040663,\n",
       " 0.7826170745808441,\n",
       " 0.778570052033147]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_retrieval(model, val_loader):\n",
    "    feats = None\n",
    "    data_ids = None\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "\n",
    "            feat = model(images, feature=True)\n",
    "            feat = feat.detach().cpu().numpy()\n",
    "\n",
    "            feat = feat/np.linalg.norm(feat, axis=1)[:, np.newaxis]\n",
    "\n",
    "            if feats is None:\n",
    "                feats = feat\n",
    "            else:\n",
    "                feats = np.append(feats, feat, axis=0)\n",
    "\n",
    "            if data_ids is None:\n",
    "                data_ids = labels\n",
    "            else:\n",
    "                data_ids = np.append(data_ids, labels, axis=0)\n",
    "\n",
    "        score_matrix = feats.dot(feats.T)\n",
    "        np.fill_diagonal(score_matrix, -np.inf)\n",
    "        top1_reference_indices = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "        top1_reference_ids = [\n",
    "            [data_ids[idx], data_ids[top1_reference_indices[idx]]] for idx in\n",
    "            range(len(data_ids))]\n",
    "\n",
    "    total_count = len(top1_reference_ids)\n",
    "    correct = 0\n",
    "    for ids in top1_reference_ids:\n",
    "        if ids[0] == ids[1]:\n",
    "            correct += 1        \n",
    "    return correct/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760950495049505"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_retrieval(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_result = [val_retrieval(model, val_loader) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7564752475247524"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7564752475247525, 0.7564752475247525, 0.7564752475247525]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494603969936404"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00523044716416355"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6546540759298516,\n",
       " 0.6394295625361341,\n",
       " 0.6442474465214878,\n",
       " 0.6489689728271343,\n",
       " 0.6478126806706495,\n",
       " 0.6587974561572557,\n",
       " 0.6544613605704375,\n",
       " 0.6481981113894777,\n",
       " 0.6481017537097706,\n",
       " 0.6499325496242051]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
