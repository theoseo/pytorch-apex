{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "from torch import nn, optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gpus = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpus = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, planes, ratio):\n",
    "\n",
    "      super(SEBlock, self).__init__()\n",
    "\n",
    "      self.se_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "      self.se_fc1 = nn.Linear(planes, planes // ratio)\n",
    "      self.relu = nn.ReLU(inplace=True)\n",
    "      self.se_fc2 = nn.Linear(planes // ratio, planes)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "      out = self.se_pool(x)\n",
    "      out = torch.flatten(out, 1)\n",
    "      out = self.se_fc1(out)\n",
    "      #print(out.shape)\n",
    "      out = F.relu(out)\n",
    "      out = self.se_fc2(out)\n",
    "      out = torch.sigmoid(out)\n",
    "      out = out.view(out.size(0), out.size(1), 1, 1)\n",
    "      #print(x.shape)\n",
    "      #print(out.shape)\n",
    "      out = torch.mul(out.expand_as(x), x)\n",
    "\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=True):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        pad = 0\n",
    "        if padding :\n",
    "            pad = (self.kernel_size - 1) // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding=pad, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_planes, momentum=0.99)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.conv(x)\n",
    "        output = self.batchnorm(output)\n",
    "        output = self.leaky_relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarknetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, out_planes):\n",
    "\n",
    "        super(DarknetBlock, self).__init__()\n",
    "        self.inplanes = out_planes * 2\n",
    "        self.conv1 = ConvBlock(self.inplanes, out_planes, 1)\n",
    "        self.conv2 = ConvBlock(out_planes, self.inplanes, 3)\n",
    "        self.se = SEBlock(self.inplanes, ratio=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2(output)\n",
    "        output = self.se(output)\n",
    "        output = output + shortcut\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "\n",
    "        super(Darknet, self).__init__()   \n",
    "\n",
    "        self.conv_block1 = ConvBlock(3, 32, 3, 1)\n",
    "        self.conv_block2 = ConvBlock(32, 64, 3, 2)\n",
    "\n",
    "        self.dark_block1 = DarknetBlock(32)\n",
    "\n",
    "        self.conv_block3 = ConvBlock(64, 128, 3, 2)\n",
    "\n",
    "        self.dark_layer1 = self._make_blocks(2, 64)\n",
    "        \n",
    "        self.conv_block4 = ConvBlock(128, 256, 3, 2)\n",
    "\n",
    "        self.dark_layer2 = self._make_blocks(2, 128)\n",
    "\n",
    "        self.conv_block5 = ConvBlock(256, 512, 3, 2)\n",
    "\n",
    "        self.dark_layer3 = self._make_blocks(2, 256)\n",
    "\n",
    "        self.conv_block6 = ConvBlock(512, 1024, 3, 2)\n",
    "\n",
    "        self.dark_layer4 = self._make_blocks(2, 512)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_blocks(self, num_blocks, out_planes):\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(DarknetBlock(out_planes))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x, feature=False):\n",
    "\n",
    "        output = self.conv_block1(x)\n",
    "        output = self.conv_block2(output)\n",
    "\n",
    "        output = self.dark_block1(output)\n",
    "\n",
    "        output = self.conv_block3(output)\n",
    "\n",
    "        output = self.dark_layer1(output)\n",
    "\n",
    "        output = self.conv_block4(output)\n",
    "\n",
    "        output = self.dark_layer2(output)\n",
    "\n",
    "        output = self.conv_block5(output)\n",
    "\n",
    "        output = self.dark_layer3(output)\n",
    "\n",
    "        output = self.conv_block6(output)\n",
    "\n",
    "        output = self.dark_layer4(output)\n",
    "\n",
    "        output = self.avgpool(output)\n",
    "\n",
    "        output = torch.flatten(output, 1)\n",
    "        \n",
    "        if feature:\n",
    "            return output\n",
    "\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(num_classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1,3,224,224))\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 101])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20705145"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using apex synced BN\n"
     ]
    }
   ],
   "source": [
    "import apex\n",
    "print(\"using apex synced BN\")\n",
    "model = apex.parallel.convert_syncbn_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1., momentum=0.9, weight_decay=5e-4, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O3:  Pure FP16 training.\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : False\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O3\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n"
     ]
    }
   ],
   "source": [
    "from apex import amp, optimizers\n",
    "\n",
    "model, optimizer = amp.initialize(model.cuda(), optimizer, opt_level='O3',keep_batchnorm_fp32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#from autoaugment import ImageNetPolicy\n",
    "\n",
    "def get_transform(random_crop=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        #mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "        #std=[x / 255.0 for x in [63.0, 62.1, 66.7]]\n",
    "        [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    transform = []\n",
    "    transform.append(transforms.Resize(256))\n",
    "    if random_crop:\n",
    "        #transform.append(transforms.RandomRotation(30))\n",
    "        transform.append(transforms.RandomResizedCrop(224))\n",
    "        transform.append(transforms.RandomHorizontalFlip())\n",
    "        transform.append(transforms.ColorJitter(hue=.05, saturation=.05),\n",
    ")\n",
    "    else:\n",
    "        transform.append(transforms.CenterCrop(224))\n",
    "    transform.append(transforms.ToTensor())\n",
    "    transform.append(normalize)\n",
    "    return transforms.Compose(transform)\n",
    "'''\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image_id, sample, target) where target is class_index of\n",
    "                the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        #print(path)\n",
    "        #print(target)\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        image_id = path.split('/')[-1]\n",
    "\n",
    "        return image_id, sample, target\n",
    "''' \n",
    "data_dir = './data/food101/'\n",
    "train_data = datasets.ImageFolder(data_dir + 'train', transform=get_transform(random_crop=True))\n",
    "test_data = datasets.ImageFolder(data_dir + 'test', transform=get_transform(random_crop=False))\n",
    "#testdata=datasets.ImageFolder(data_dir + r'\\test', transform=test_transforms)\n",
    "\n",
    "#trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(test_data, batch_size=128)\n",
    "#test_loader=torch.utils.data.DataLoader(testdata, batch_size=64)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "#data_dir = 'train/train_data'\n",
    "\n",
    "#dataset = CustomDataset(data_dir, transform=get_transform(random_crop=True))\n",
    "\n",
    "#split_size = int(len(dataset) * 0.9)\n",
    "#train_set, valid_set = data.random_split(dataset, [split_size, len(dataset) - split_size])\n",
    "tr_loader = data.DataLoader(dataset=train_data,\n",
    "                            batch_size=256,\n",
    "                            #sampler = RandomIdentitySampler(train_set, 4),\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=16)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=test_data,\n",
    "                             batch_size=256,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True,                             \n",
    "                             num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 224, 224])\n",
      "tensor([ 38,  63,   8,  36,  35,  89,  54,  36,  96,  63,  48,  12,  42,  91,\n",
      "         80,  88,  24,   9,  31,  46,  25,  48,  39,  76,   3,  56,  52,  93,\n",
      "         55,   7,  89,  76,   7,  10,  76,  31,   5,  29,   8,  84,  94,  84,\n",
      "          7,   6,  31,  58,  60,  70,   0,  52,   2,  12,  27,  92,  19,  12,\n",
      "         15,   5,  17,  28,  99,  72,  15,  30,  67,  86,  57,  58,  47,  55,\n",
      "         56,  29,  31,  85,   2,   2,  26,  56,  83,  46,  34,  19,  58,  51,\n",
      "         34,  98,  79,  18,  15,  76,  11,  40,  85,  47,  38,   5,  36,  27,\n",
      "         82,   5,   9,  99,  81,  87,  81,   1,  56,  73,   4,  34,  55,   2,\n",
      "         72,  71,   6,  75,  50,  67,  91,  94,  72,   6,  27,  28,  65,  93,\n",
      "         32,  56,  13,  56,  29,  29,  90,  25,  30,  73,  86,  32,  23,  73,\n",
      "         42,  86,  57,  65,  50,  51,  78,  60,  37,  95,  41,  25,  94,  27,\n",
      "         42,  72,  84,  40,  56,  64,  41,  47,  37,  83,  89,  64,  76,  37,\n",
      "         66,  98,  14,  19,  24,  22,  80,  69,  63,  72,  13,  14,   4,  29,\n",
      "         59,   4,  48,  43,  29,  62,  65,  84,  96,  35,  81,  12,  90,  59,\n",
      "         66,  24,  29,  29,  59,   7,  31,  90,  24,  34,  98,   7,  38,  51,\n",
      "         89,  65,  63,  85,  34,  19,   3,  13,  69,  74,  14,  36,   3,  77,\n",
      "         25,  91,  56,   5,  97,  99,  75,  52,   2,  13,  10,   1,  97,  30,\n",
      "         26,  18,  65, 100,  87,  61,   7,  36,  82,  31,  86,  67,  88,  96,\n",
      "         51,  38,  19,  57])\n",
      "torch.Size([256, 3, 224, 224])\n",
      "tensor([85, 24, 16, 62,  2,  1, 28, 12, 65,  8, 16,  3, 17, 97, 71, 82, 44, 23,\n",
      "        61, 94,  0, 84, 60, 63, 76, 10, 54, 81, 15, 83,  5, 51, 32, 50, 77, 46,\n",
      "        41, 35, 98,  6, 35,  9, 58, 98, 30, 46, 77,  6, 38, 49, 41, 58, 55,  6,\n",
      "        61, 51, 32,  4, 66, 79, 31, 22, 82, 49, 75, 82, 72, 92, 59,  5, 27, 18,\n",
      "        78, 37, 40, 69, 85,  2, 67, 12, 64, 81, 13, 57, 36, 46, 41, 92, 13, 91,\n",
      "         2, 77, 89, 11,  0, 91, 96, 98, 70, 86, 42,  8, 38, 75, 93, 83, 40, 29,\n",
      "        82, 33, 86, 21, 38, 97, 83, 79, 61, 29, 89, 85, 40, 74, 16, 39, 14, 61,\n",
      "        87, 18, 18, 81, 22, 82, 63, 58, 43, 32, 33, 86, 45, 21, 37,  1, 28, 89,\n",
      "        41, 86, 39, 30, 25, 57,  1,  2, 45, 27, 38, 20, 91, 49, 35, 96, 84, 71,\n",
      "        93, 71, 69,  0, 96, 29, 50, 75, 36, 58, 36, 40, 21, 35,  7, 11, 41, 91,\n",
      "         2, 48, 35, 60, 34, 72, 38, 21, 70, 27, 19, 13, 23, 40, 69, 35,  1, 79,\n",
      "        90, 94, 65, 16, 30, 33,  4,  8,  5,  8, 95, 62, 82, 12, 45, 32, 33, 62,\n",
      "         2, 30,  4, 60, 44, 48, 72, 52, 58, 25, 87, 90, 67, 62, 71, 83, 89, 79,\n",
      "        23, 46, 10, 81, 80, 14, 64, 69, 14, 94, 99, 27, 85, 87, 19, 30, 88, 65,\n",
      "        73, 40, 69, 10])\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    inputs, labels = next(iter(tr_loader))\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "model.train()\n",
    "for _ in range(2):\n",
    "    inputs, labels = next(iter(tr_loader))\n",
    "    print(1)\n",
    "    inputs = inputs.cuda(non_blocking=True)        \n",
    "    labels = labels.cuda(non_blocking=True)    \n",
    "    print(2)    \n",
    "    logits = model(inputs)\n",
    "    print(3)                       \n",
    "    loss = criterion(logits, labels)                   \n",
    "    print(4)                   \n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "    print(5)                            \n",
    "    model.zero_grad()\n",
    "    print(10)                                \n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(tr_loader)\n",
    "                                                , epochs=30, pct_start=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 99/296]\tBatch 64.287 (36.305)\tData 63.984 (35.992)\tLoss 4.22977 (4.41971)\tAcc@1   8.20 (  4.57)\tAcc@5  21.88 ( 15.30)\tLearningRate 0.00475 (0.00425)\n",
      "Epoch: [0][199/296]\tBatch 117.982 (63.512)\tData 117.677 (63.201)\tLoss 4.17639 (4.31217)\tAcc@1   7.42 (  5.90)\tAcc@5  22.66 ( 18.63)\tLearningRate 0.00698 (0.00500)\n",
      "0:02:47.008971 elapsed for 1\n",
      "Epoch: [1][ 99/296]\tBatch 63.134 (75.859)\tData 62.827 (75.548)\tLoss 3.81145 (4.17136)\tAcc@1  13.28 (  7.83)\tAcc@5  35.16 ( 22.95)\tLearningRate 0.01531 (0.00785)\n",
      "Epoch: [1][199/296]\tBatch 116.869 (78.644)\tData 116.571 (78.334)\tLoss 3.65064 (4.10218)\tAcc@1  16.80 (  8.91)\tAcc@5  36.72 ( 25.11)\tLearningRate 0.02134 (0.00995)\n",
      "0:02:44.247565 elapsed for 2\n",
      "Epoch: [2][ 99/296]\tBatch 63.309 (81.208)\tData 63.007 (80.897)\tLoss 3.54228 (3.95612)\tAcc@1  16.41 ( 11.15)\tAcc@5  44.53 ( 29.44)\tLearningRate 0.03572 (0.01515)\n",
      "Epoch: [2][199/296]\tBatch 116.908 (82.241)\tData 116.611 (81.931)\tLoss 3.29222 (3.88049)\tAcc@1  21.09 ( 12.46)\tAcc@5  46.09 ( 31.65)\tLearningRate 0.04393 (0.01827)\n",
      "0:02:44.649943 elapsed for 3\n",
      "Epoch: [3][ 99/296]\tBatch 63.803 (83.400)\tData 63.472 (83.090)\tLoss 3.29700 (3.73317)\tAcc@1  21.48 ( 15.02)\tAcc@5  52.34 ( 35.79)\tLearningRate 0.06049 (0.02501)\n",
      "Epoch: [3][199/296]\tBatch 116.830 (84.027)\tData 116.532 (83.717)\tLoss 2.83352 (3.66134)\tAcc@1  32.03 ( 16.35)\tAcc@5  60.16 ( 37.73)\tLearningRate 0.06868 (0.02866)\n",
      "0:02:44.037896 elapsed for 4\n",
      "Epoch: [4][ 99/296]\tBatch 62.850 (84.585)\tData 62.548 (84.275)\tLoss 2.51811 (3.52884)\tAcc@1  35.16 ( 18.85)\tAcc@5  60.94 ( 41.19)\tLearningRate 0.08299 (0.03590)\n",
      "Epoch: [4][199/296]\tBatch 116.378 (84.929)\tData 116.058 (84.619)\tLoss 2.47094 (3.46657)\tAcc@1  39.45 ( 20.01)\tAcc@5  65.62 ( 42.77)\tLearningRate 0.08896 (0.03953)\n",
      "0:02:43.884487 elapsed for 5\n",
      "Epoch: [5][ 99/296]\tBatch 63.809 (85.306)\tData 63.502 (84.996)\tLoss 2.33745 (3.35175)\tAcc@1  43.36 ( 22.23)\tAcc@5  66.80 ( 45.62)\tLearningRate 0.09717 (0.04622)\n",
      "Epoch: [5][199/296]\tBatch 117.754 (85.611)\tData 117.451 (85.301)\tLoss 2.47719 (3.29742)\tAcc@1  37.50 ( 23.29)\tAcc@5  65.23 ( 46.95)\tLearningRate 0.09932 (0.04933)\n",
      "0:02:45.532825 elapsed for 6\n",
      "Epoch: [6][ 99/296]\tBatch 64.028 (85.897)\tData 63.719 (85.587)\tLoss 2.27642 (3.19736)\tAcc@1  41.80 ( 25.30)\tAcc@5  72.27 ( 49.35)\tLearningRate 0.09995 (0.05461)\n",
      "Epoch: [6][199/296]\tBatch 116.968 (86.103)\tData 116.652 (85.793)\tLoss 2.17218 (3.15000)\tAcc@1  44.53 ( 26.27)\tAcc@5  70.70 ( 50.47)\tLearningRate 0.09980 (0.05690)\n",
      "0:02:45.048240 elapsed for 7\n",
      "Epoch: [7][ 99/296]\tBatch 63.076 (86.311)\tData 62.760 (86.002)\tLoss 2.14553 (3.06287)\tAcc@1  44.92 ( 28.03)\tAcc@5  73.83 ( 52.48)\tLearningRate 0.09923 (0.06075)\n",
      "Epoch: [7][199/296]\tBatch 116.412 (86.446)\tData 116.096 (86.137)\tLoss 2.14406 (3.02119)\tAcc@1  47.66 ( 28.89)\tAcc@5  73.05 ( 53.43)\tLearningRate 0.09880 (0.06243)\n",
      "0:02:44.148706 elapsed for 8\n",
      "Epoch: [8][ 99/296]\tBatch 62.343 (86.519)\tData 62.039 (86.209)\tLoss 2.16665 (2.94362)\tAcc@1  48.05 ( 30.48)\tAcc@5  72.27 ( 55.17)\tLearningRate 0.09767 (0.06528)\n",
      "Epoch: [8][199/296]\tBatch 114.783 (86.602)\tData 114.463 (86.292)\tLoss 1.83245 (2.90747)\tAcc@1  57.03 ( 31.24)\tAcc@5  77.34 ( 55.97)\tLearningRate 0.09696 (0.06653)\n",
      "0:02:43.434701 elapsed for 9\n",
      "Epoch: [9][ 99/296]\tBatch 63.439 (86.670)\tData 63.140 (86.360)\tLoss 1.75366 (2.84050)\tAcc@1  57.42 ( 32.66)\tAcc@5  82.81 ( 57.44)\tLearningRate 0.09529 (0.06863)\n",
      "Epoch: [9][199/296]\tBatch 117.273 (86.795)\tData 116.973 (86.485)\tLoss 1.71133 (2.80783)\tAcc@1  56.64 ( 33.34)\tAcc@5  81.64 ( 58.15)\tLearningRate 0.09431 (0.06954)\n",
      "0:02:45.323146 elapsed for 10\n",
      "Epoch: [10][ 99/296]\tBatch 63.860 (86.899)\tData 63.557 (86.590)\tLoss 1.87236 (2.74798)\tAcc@1  52.73 ( 34.60)\tAcc@5  77.34 ( 59.44)\tLearningRate 0.09214 (0.07106)\n",
      "Epoch: [10][199/296]\tBatch 117.864 (87.001)\tData 117.565 (86.692)\tLoss 1.71583 (2.71988)\tAcc@1  55.47 ( 35.19)\tAcc@5  81.64 ( 60.03)\tLearningRate 0.09091 (0.07171)\n",
      "0:02:44.701432 elapsed for 11\n",
      "Epoch: [11][ 99/296]\tBatch 63.839 (87.054)\tData 63.540 (86.744)\tLoss 1.79076 (2.66694)\tAcc@1  55.08 ( 36.31)\tAcc@5  80.47 ( 61.16)\tLearningRate 0.08827 (0.07275)\n",
      "Epoch: [11][199/296]\tBatch 116.282 (87.125)\tData 115.983 (86.815)\tLoss 1.82061 (2.64207)\tAcc@1  57.42 ( 36.83)\tAcc@5  76.17 ( 61.69)\tLearningRate 0.08681 (0.07318)\n",
      "0:02:44.034707 elapsed for 12\n",
      "Epoch: [12][ 99/296]\tBatch 63.137 (87.142)\tData 62.839 (86.832)\tLoss 1.56148 (2.59470)\tAcc@1  63.28 ( 37.84)\tAcc@5  85.55 ( 62.68)\tLearningRate 0.08374 (0.07383)\n",
      "Epoch: [12][199/296]\tBatch 116.543 (87.203)\tData 116.245 (86.893)\tLoss 1.83045 (2.57117)\tAcc@1  55.08 ( 38.34)\tAcc@5  76.17 ( 63.16)\tLearningRate 0.08208 (0.07407)\n",
      "0:02:44.654080 elapsed for 13\n",
      "Epoch: [13][ 99/296]\tBatch 63.638 (87.244)\tData 63.334 (86.934)\tLoss 1.51977 (2.52827)\tAcc@1  61.72 ( 39.25)\tAcc@5  83.20 ( 64.05)\tLearningRate 0.07864 (0.07438)\n",
      "Epoch: [13][199/296]\tBatch 119.584 (87.347)\tData 119.285 (87.037)\tLoss 1.59318 (2.50756)\tAcc@1  58.59 ( 39.70)\tAcc@5  85.16 ( 64.47)\tLearningRate 0.07680 (0.07447)\n",
      "0:02:46.844050 elapsed for 14\n",
      "Epoch: [14][ 99/296]\tBatch 64.206 (87.442)\tData 63.906 (87.132)\tLoss 1.48155 (2.46769)\tAcc@1  69.14 ( 40.55)\tAcc@5  84.77 ( 65.29)\tLearningRate 0.07304 (0.07449)\n",
      "Epoch: [14][199/296]\tBatch 117.546 (87.513)\tData 117.246 (87.203)\tLoss 1.59546 (2.44825)\tAcc@1  53.91 ( 40.98)\tAcc@5  83.20 ( 65.68)\tLearningRate 0.07106 (0.07443)\n",
      "0:02:45.382449 elapsed for 15\n",
      "Epoch: [15][ 99/296]\tBatch 62.391 (87.527)\tData 62.016 (87.217)\tLoss 1.63171 (2.41234)\tAcc@1  61.72 ( 41.75)\tAcc@5  82.81 ( 66.40)\tLearningRate 0.06705 (0.07420)\n",
      "Epoch: [15][199/296]\tBatch 115.811 (87.555)\tData 115.512 (87.245)\tLoss 1.49504 (2.39435)\tAcc@1  62.50 ( 42.14)\tAcc@5  85.55 ( 66.76)\tLearningRate 0.06496 (0.07402)\n",
      "0:02:43.316165 elapsed for 16\n",
      "Epoch: [16][ 99/296]\tBatch 62.739 (87.534)\tData 62.396 (87.224)\tLoss 1.61338 (2.36017)\tAcc@1  57.03 ( 42.89)\tAcc@5  82.81 ( 67.44)\tLearningRate 0.06077 (0.07357)\n",
      "Epoch: [16][199/296]\tBatch 116.503 (87.566)\tData 116.194 (87.255)\tLoss 1.65425 (2.34393)\tAcc@1  56.64 ( 43.24)\tAcc@5  85.16 ( 67.76)\tLearningRate 0.05860 (0.07329)\n",
      "0:02:44.814263 elapsed for 17\n",
      "Epoch: [17][ 99/296]\tBatch 62.530 (87.574)\tData 62.191 (87.263)\tLoss 1.53236 (2.31260)\tAcc@1  62.50 ( 43.91)\tAcc@5  85.16 ( 68.38)\tLearningRate 0.05431 (0.07265)\n",
      "Epoch: [17][199/296]\tBatch 116.781 (87.606)\tData 116.465 (87.295)\tLoss 1.51408 (2.29705)\tAcc@1  60.94 ( 44.25)\tAcc@5  88.67 ( 68.69)\tLearningRate 0.05210 (0.07227)\n",
      "0:02:45.549785 elapsed for 18\n",
      "Epoch: [18][ 99/296]\tBatch 64.091 (87.621)\tData 63.786 (87.311)\tLoss 1.41855 (2.26731)\tAcc@1  64.06 ( 44.90)\tAcc@5  83.98 ( 69.26)\tLearningRate 0.04777 (0.07147)\n",
      "Epoch: [18][199/296]\tBatch 117.614 (87.677)\tData 117.311 (87.366)\tLoss 1.51641 (2.25269)\tAcc@1  58.98 ( 45.22)\tAcc@5  87.89 ( 69.54)\tLearningRate 0.04556 (0.07102)\n",
      "0:02:45.193749 elapsed for 19\n",
      "Epoch: [19][ 99/296]\tBatch 62.914 (87.701)\tData 62.609 (87.390)\tLoss 1.44532 (2.22449)\tAcc@1  62.89 ( 45.85)\tAcc@5  85.16 ( 70.08)\tLearningRate 0.04127 (0.07007)\n",
      "Epoch: [19][199/296]\tBatch 117.866 (87.741)\tData 117.565 (87.430)\tLoss 1.34322 (2.21060)\tAcc@1  64.06 ( 46.16)\tAcc@5  86.72 ( 70.34)\tLearningRate 0.03910 (0.06956)\n",
      "0:02:45.309621 elapsed for 20\n",
      "Epoch: [20][ 99/296]\tBatch 62.819 (87.754)\tData 62.505 (87.442)\tLoss 1.19274 (2.18341)\tAcc@1  70.31 ( 46.77)\tAcc@5  89.06 ( 70.85)\tLearningRate 0.03492 (0.06850)\n",
      "Epoch: [20][199/296]\tBatch 118.059 (87.799)\tData 117.744 (87.488)\tLoss 1.41847 (2.17011)\tAcc@1  63.28 ( 47.07)\tAcc@5  85.16 ( 71.10)\tLearningRate 0.03282 (0.06793)\n",
      "0:02:44.883877 elapsed for 21\n",
      "Epoch: [21][ 99/296]\tBatch 64.271 (87.813)\tData 63.960 (87.502)\tLoss 1.37518 (2.14347)\tAcc@1  65.23 ( 47.66)\tAcc@5  85.16 ( 71.59)\tLearningRate 0.02882 (0.06678)\n",
      "Epoch: [21][199/296]\tBatch 118.645 (87.858)\tData 118.344 (87.547)\tLoss 1.31183 (2.13082)\tAcc@1  67.58 ( 47.95)\tAcc@5  86.72 ( 71.82)\tLearningRate 0.02684 (0.06617)\n",
      "0:02:45.711365 elapsed for 22\n",
      "Epoch: [22][ 99/296]\tBatch 63.643 (87.882)\tData 63.300 (87.570)\tLoss 1.12280 (2.10561)\tAcc@1  67.19 ( 48.51)\tAcc@5  90.23 ( 72.27)\tLearningRate 0.02309 (0.06495)\n",
      "Epoch: [22][199/296]\tBatch 117.352 (87.912)\tData 117.036 (87.600)\tLoss 1.65135 (2.09308)\tAcc@1  59.38 ( 48.79)\tAcc@5  79.69 ( 72.50)\tLearningRate 0.02126 (0.06431)\n",
      "0:02:45.339074 elapsed for 23\n",
      "Epoch: [23][ 99/296]\tBatch 63.832 (87.917)\tData 63.525 (87.605)\tLoss 1.21396 (2.06780)\tAcc@1  69.92 ( 49.36)\tAcc@5  87.50 ( 72.95)\tLearningRate 0.01782 (0.06304)\n",
      "Epoch: [23][199/296]\tBatch 116.568 (87.947)\tData 116.263 (87.635)\tLoss 1.19426 (2.05523)\tAcc@1  69.53 ( 49.65)\tAcc@5  86.72 ( 73.17)\tLearningRate 0.01616 (0.06238)\n",
      "0:02:44.607371 elapsed for 24\n",
      "Epoch: [24][ 99/296]\tBatch 63.484 (87.939)\tData 63.179 (87.627)\tLoss 1.07300 (2.03024)\tAcc@1  72.27 ( 50.22)\tAcc@5  90.62 ( 73.60)\tLearningRate 0.01310 (0.06108)\n",
      "Epoch: [24][199/296]\tBatch 118.165 (87.965)\tData 117.820 (87.653)\tLoss 0.98104 (2.01765)\tAcc@1  76.56 ( 50.50)\tAcc@5  91.80 ( 73.82)\tLearningRate 0.01165 (0.06042)\n",
      "0:02:45.806772 elapsed for 25\n",
      "Epoch: [25][ 99/296]\tBatch 63.866 (87.985)\tData 63.566 (87.673)\tLoss 0.86476 (1.99277)\tAcc@1  75.00 ( 51.07)\tAcc@5  93.36 ( 74.25)\tLearningRate 0.00901 (0.05911)\n",
      "Epoch: [25][199/296]\tBatch 118.330 (88.020)\tData 118.015 (87.708)\tLoss 1.00463 (1.98001)\tAcc@1  75.78 ( 51.37)\tAcc@5  89.45 ( 74.46)\tLearningRate 0.00779 (0.05844)\n",
      "0:02:45.236684 elapsed for 26\n",
      "Epoch: [26][ 99/296]\tBatch 63.755 (88.039)\tData 63.454 (87.726)\tLoss 1.07283 (1.95500)\tAcc@1  70.31 ( 51.94)\tAcc@5  88.67 ( 74.88)\tLearningRate 0.00563 (0.05714)\n",
      "Epoch: [26][199/296]\tBatch 117.708 (88.068)\tData 117.401 (87.756)\tLoss 0.86568 (1.94211)\tAcc@1  78.52 ( 52.24)\tAcc@5  92.97 ( 75.09)\tLearningRate 0.00465 (0.05648)\n",
      "0:02:46.223794 elapsed for 27\n",
      "Epoch: [27][ 99/296]\tBatch 63.973 (88.081)\tData 63.663 (87.768)\tLoss 0.88760 (1.91679)\tAcc@1  75.39 ( 52.83)\tAcc@5  91.41 ( 75.51)\tLearningRate 0.00300 (0.05520)\n",
      "Epoch: [27][199/296]\tBatch 116.978 (88.107)\tData 116.670 (87.795)\tLoss 0.92816 (1.90396)\tAcc@1  75.39 ( 53.13)\tAcc@5  92.58 ( 75.71)\tLearningRate 0.00229 (0.05456)\n",
      "0:02:45.687734 elapsed for 28\n",
      "Epoch: [28][ 99/296]\tBatch 63.797 (88.112)\tData 63.480 (87.800)\tLoss 0.64929 (1.87914)\tAcc@1  82.42 ( 53.71)\tAcc@5  94.53 ( 76.11)\tLearningRate 0.00117 (0.05333)\n",
      "Epoch: [28][199/296]\tBatch 117.655 (88.140)\tData 117.351 (87.828)\tLoss 0.80787 (1.86641)\tAcc@1  81.64 ( 54.01)\tAcc@5  90.62 ( 76.31)\tLearningRate 0.00075 (0.05271)\n",
      "0:02:45.673206 elapsed for 29\n",
      "Epoch: [29][ 99/296]\tBatch 62.633 (88.144)\tData 62.328 (87.832)\tLoss 0.76953 (1.84247)\tAcc@1  79.69 ( 54.58)\tAcc@5  94.53 ( 76.69)\tLearningRate 0.00019 (0.05153)\n",
      "Epoch: [29][199/296]\tBatch 118.949 (88.166)\tData 118.644 (87.853)\tLoss 0.80801 (1.83035)\tAcc@1  79.30 ( 54.87)\tAcc@5  91.80 ( 76.88)\tLearningRate 0.00004 (0.05094)\n",
      "0:02:45.612747 elapsed for 30\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "high = 0.0\n",
    "epoch_time = AverageMeter('Epoch', ':6.3f')\n",
    "batch_time = AverageMeter('Batch', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "losses = AverageMeter('Loss', ':.5f')\n",
    "learning_rates = AverageMeter('LearningRate', ':.5f')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    time_ = datetime.datetime.now()    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    progress = ProgressMeter(\n",
    "        len(tr_loader),\n",
    "        [batch_time, data_time, losses, top1, top5, learning_rates],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    end = time.time()    \n",
    "    for i, (inputs, labels) in enumerate(tr_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #print(inputs.shape)\n",
    "        #print(labels.shape)\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs = inputs.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #_, preds = torch.max(outputs, 1)\n",
    "        #loss.backward()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # print statistics\n",
    "        acc1, acc5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        learning_rates.update(scheduler.get_lr()[0])        \n",
    "        top1.update(acc1[0], inputs.size(0))\n",
    "        top5.update(acc5[0], inputs.size(0))\n",
    "\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            progress.display(i)\n",
    "            #running_loss = 0.0\n",
    "    elapsed = datetime.datetime.now() - time_\n",
    "    print('{} elapsed for {}'.format(elapsed, epoch+1))\n",
    "\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': loss,    \n",
    "    \n",
    "}, './checkpoint/food_darknet25_fp16_5e4_ep030.b0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_val(model, val_loader):\n",
    "    correct = 0\n",
    "    total = 0    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_results = classification_val(model, val_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268118811881188"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161584158415841"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405,\n",
       " 0.8245940594059405]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828868760840239"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002308887647354633"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7867604548082482,\n",
       " 0.7841587974561572,\n",
       " 0.783773366737329,\n",
       " 0.7795336288302178,\n",
       " 0.7843515128155714,\n",
       " 0.7842551551358643,\n",
       " 0.7832915783387936,\n",
       " 0.7815571401040663,\n",
       " 0.7826170745808441,\n",
       " 0.778570052033147]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_retrieval(model, val_loader):\n",
    "    feats = None\n",
    "    data_ids = None\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "\n",
    "            feat = model(images, feature=True)\n",
    "            feat = feat.detach().cpu().numpy()\n",
    "\n",
    "            feat = feat/np.linalg.norm(feat, axis=1)[:, np.newaxis]\n",
    "\n",
    "            if feats is None:\n",
    "                feats = feat\n",
    "            else:\n",
    "                feats = np.append(feats, feat, axis=0)\n",
    "\n",
    "            if data_ids is None:\n",
    "                data_ids = labels\n",
    "            else:\n",
    "                data_ids = np.append(data_ids, labels, axis=0)\n",
    "\n",
    "        score_matrix = feats.dot(feats.T)\n",
    "        np.fill_diagonal(score_matrix, -np.inf)\n",
    "        top1_reference_indices = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "        top1_reference_ids = [\n",
    "            [data_ids[idx], data_ids[top1_reference_indices[idx]]] for idx in\n",
    "            range(len(data_ids))]\n",
    "\n",
    "    total_count = len(top1_reference_ids)\n",
    "    correct = 0\n",
    "    for ids in top1_reference_ids:\n",
    "        if ids[0] == ids[1]:\n",
    "            correct += 1        \n",
    "    return correct/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760950495049505"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_retrieval(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_result = [val_retrieval(model, val_loader) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7564752475247524"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7564752475247525, 0.7564752475247525, 0.7564752475247525]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494603969936404"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00523044716416355"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6546540759298516,\n",
       " 0.6394295625361341,\n",
       " 0.6442474465214878,\n",
       " 0.6489689728271343,\n",
       " 0.6478126806706495,\n",
       " 0.6587974561572557,\n",
       " 0.6544613605704375,\n",
       " 0.6481981113894777,\n",
       " 0.6481017537097706,\n",
       " 0.6499325496242051]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
